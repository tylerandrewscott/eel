#CGR_participants = sample(seq(n_agents),20)
#communication --- sharing and learning distortion
#shared motivation --- willingness to contribute
#joint action --- thinking like a team (group payout)
AgentContribution = function(payoff_estimate,motivation,reciprocity,payoff,contribution,issue){
if(t == 1){updated_motivation = motivation}
if(t > 1){updated_motivation = motivation * 0.8 + reciprocity * 0.1 + {payoff > contribution} * 0.1}
donate = (runif(1,min = 0,max = 1) < updated_motivation)+0 * issue
donation_amount = payoff_estimate * updated_motivation * donate
return(data.table(contribution = donation_amount,motivation = updated_motivation))
}
agent_issue_binary = as.sociomatrix(agent_issue_network)
for(t in seq(periods)){
print(t)
for(i in seq(n_issues)){
#update estimates
#agents revise up or down based on their payout from last time
if(t == 1){payoff_estimates_matrix[,i,t]<-ifelse(is.na(payoff_estimates[,i]),0,payoff_estimates[,i])}
if(t != 1){payoff_estimates_matrix[,i,t] <- payoff_estimates_matrix[,i,t-1]}
# + {payout_matrix[,i,t-1] - contrib_matrix[,i,t-1]}}
issue_i_contribution_result = rbindlist(lapply(seq(n_agents),function(a) AgentContribution(payoff_estimate = payoff_estimates_matrix[a,i,t],
motivation = motivation_matrix[a,i,t],
payoff = payout_matrix[a,i,t-1],issue = agent_issue_binary[a,i],
reciprocity = reciprocity_matrix[a,i,t-1],
contribution = contrib_matrix[a,i,t-1])))
contrib_matrix[,i,t]<-issue_i_contribution_result$contribution
if(t!=periods){motivation_matrix[,i,t+1]<-issue_i_contribution_result$motivation}
payout_matrix[,i,t] <- {sum(contrib_matrix[,i,t] * issue_payoffs[i]) / {sum(agent_issue_binary[,i])}} * agent_issue_binary[,i]
reciprocity_matrix[,i,t] <- sapply(seq(n_agents),function(x) payout_matrix[x,i,t] > {motivation_matrix[x,i,t] * contrib_matrix[x,i,t] * agent_post_sharing_payoff_estimates[[x]][i]})
}
}
motivation * contribution * estimated_payoff
pg_results = data.table(melt(payout_matrix))
goods_by_time = pg_results[,sum(value,na.rm = T),by=.(Var2,Var3)]
ggplot(goods_by_time,aes(x = Var3,y = V1,group = Var2,col = as.factor(Var2))) +
geom_path() + #geom_point() +
ylab('Public goods produced') + xlab('time period') +
ggtitle('100 public goods over 20 periods','no CGR inserted')
require(data.table)
require(pbapply)
require(statnet)
require(lsa)
library(fields)
library(ggraph)
require(Matrix)
require(purrr)
require(tidyverse)
#specify working parameters
n_agents = 50
n_issues = 4
periods = 50
n_info_pieces = 1
info_uncertainty = 1
n_agent_per_issue = 50
range_of_motivation = c(0.1,0.9)
range_of_communication = c(0.1,0.9)
range_of_capacity = c(0.1,0.9)
min_payout = 0;max_payout = 5
createCGR = TRUE
## robustness:
#knockout nodes
#shuffle payoffs
#CGR DRIVERS:
#initiating leadership: smart invitations?
#uncertainty: sampling distribution for payout information
### THESE TWO ARE SORT OF IMPLICITY IN THE PUBLIC GOODS GAME -- MORE NEEDED?
#consequential incentives: needed? maybe not -- players do win and lose here -- how can we adjust BATNA?
#interdependence: how can we tie goods together?
#initial agent attributes
agent_attributes = list(motivation = runif(n_agents,range_of_motivation[1],range_of_motivation[2]),
communication = runif(n_agents,range_of_communication[1],range_of_communication[2]),
capacity = runif(n_agents,range_of_capacity[1],range_of_capacity[2]))
#initialize agent network
agent_net = network(matrix(0,ncol=n_agents,nrow=n_agents),directed = T,vertex.attr = agent_attributes)
#initialize agent-issue network with placeholder 1 and 0 values to fix density
issue_agent_list = lapply(seq(n_issues),function(x) sort(sample(x = seq(n_agents),size = n_agent_per_issue,replace = F)))
agent_issue_matrix = sapply(issue_agent_list,function(x) {x %in% seq(n_agents)}+0)
# start_agent_issue_net = cbind(matrix(1,ncol = n_agent_focal_issues,nrow = n_agents),matrix(0,ncol = n_issues - n_agent_per_issue,nrow = n_agents))
# agent_issue_network = do.call(cbind,replicate(n_agents,sample(c(rep(1,n_agent_focal_issues),rep(0,n_issues - n_agent_per_issue)),replace = F),simplify = F))
# agent_issue_network = simulate(as.network(agent_issue_network,bipartite = T,directed = F,matrix.type = 'incidence')~ edges,
#                                constraints = ~edges + bd(maxin =10,maxout = 10,minout = 5))
agent_issue_network = agent_issue_matrix
#compute agent homophily based on shared issues
agent_issue_homophily <- cosine(t(agent_issue_network))
#compute issue homophily based on shared agents
issue_agent_homophily <- cosine(agent_issue_network)
seed_network = network(rgraph(n_agents,tprob = 0.04),directed = F)
sqrt_cosim = sqrt(agent_issue_homophily)
diag(sqrt_cosim) <- 0
if(n_agent_per_issue==n_agents){
agent_network = (simulate(seed_network ~ edges + isolates + gwdegree(0.5,fixed = T) + gwesp(0.5,fixed = T),coef = c(-2,-Inf,-0.75,0.75),constraints = ~edges))
}
if(n_agent_per_issue==n_agents){
agent_network = (simulate(seed_network ~ edges + isolates + gwdegree(0.5,fixed = T) + gwesp(0.5,fixed = T) +
edgecov(sqrt_cosim),coef = c(-2,-Inf,-0.75,0.75,1),constraints = ~edges))
}
# issue_network = rgraph(n = nrow(issue_agent_homophily),tprob = 0.025, mode = 'graph')
# if(n_agent_per_issue==n_agents){
# issue_network = (simulate(network(issue_network,directed = F) ~ edges + isolates,coef = c(-2,-Inf),
#                           constraints = ~ edges))
# }
# if(n_agent_per_issue!=n_agents){
#   issue_network = (simulate(network(issue_network,directed = F) ~ edges + edgecov(sqrt(issue_agent_homophily)) + isolates,coef = c(-5,2,-Inf),
#                             constraints = ~ edges + bd(minin = 2)))
# }
issue_payoffs = runif(n = n_issues,min_payout,max_payout)
# payoff_info_matrix = do.call(cbind,lapply(issue_payoffs,rnorm, n = n_info_pieces,sd = info_uncertainty))
#
# mask_info = function(info_matrix,pieces_kept){
#   mask_locations = sample(length(info_matrix),length(info_matrix)-pieces_kept,replace = F)
#   info_matrix[mask_locations]<-NA
#   return(info_matrix)
# }
# agent_info_matrices = lapply(1:n_agents,function(x) mask_info(info_matrix = payoff_info_matrix,pieces_kept = n_info_pieces))
agent_info_matrices  = replicate(n_agents,sapply(issue_payoffs,rnorm, n = n_info_pieces,sd =info_uncertainty),simplify = F)
agent_info_shared = mapply(function(info,distortion) info * distortion,info = agent_info_matrices,distortion = agent_attributes$communication,SIMPLIFY = F)
require(abind)
agent_edge_index = data.table(which(as.sociomatrix(agent_network)==1,arr.ind = T))
agent_alters = lapply(seq(n_agents),function(x) agent_edge_index[col == x,]$col)
agent_issue_edge_index = data.table(which(agent_issue_network==1,arr.ind = T))
agent_issues = lapply(seq(n_agents),function(x) agent_issue_edge_index[row == x,]$col)
AgentInfoHeard = function(alters,available_info,distortion){
colMeans(do.call(rbind,available_info[alters]) * distortion,na.rm = T)}
agent_info_received = lapply(seq_along(agent_alters),function(x){if(length(agent_alters[[x]])==0){matrix(NA,ncol = n_issues)}else{
AgentInfoHeard(alters = agent_alters[[x]],distortion = agent_attributes$communication[x],available_info = agent_info_shared)}})
agent_post_sharing_payoff_estimates = mapply(function(x,y) colMeans(rbind(x,y),na.rm = T),x = agent_info_matrices,y = agent_info_received,SIMPLIFY = F)
payoff_estimates = do.call(rbind,agent_post_sharing_payoff_estimates)
payoff_estimates_matrix  = motivation_matrix = contrib_matrix = payout_matrix = reciprocity_matrix  = array(NA,dim = c(n_agents,n_issues,periods))
contributors_matrix = array(NA,dim = c(1,n_issues,periods))
motivation_matrix[,,1] <- agent_attributes$motivation * as.sociomatrix(agent_issue_network)
#### FIX: TIE GOODS CONTRIBUTIONS AND PAYOUTS TO BIPARTITE NETWORK
### CGR INNOVATION IS TO PAIR THINGS UP
#CGR_issues = sample(seq(n_issues),20)
#CGR_participants = sample(seq(n_agents),20)
#communication --- sharing and learning distortion
#shared motivation --- willingness to contribute
#joint action --- thinking like a team (group payout)
AgentContribution = function(payoff_estimate,motivation,reciprocity,payoff,buyin,issue){
if(t == 1){updated_motivation = motivation}
if(t > 1){updated_motivation = motivation * 0.8 + reciprocity * 0.1 + buyin * 0.1}
donate = (runif(1,min = 0,max = 1) < updated_motivation)+0 * issue
donation_amount = payoff_estimate * updated_motivation * donate
return(data.table(contribution = donation_amount,motivation = updated_motivation))
}
agent_issue_binary = as.sociomatrix(agent_issue_network)
for(t in seq(periods)){
print(t)
for(i in seq(n_issues)){
#update estimates
#agents revise up or down based on their payout from last time
if(t == 1){payoff_estimates_matrix[,i,t]<-ifelse(is.na(payoff_estimates[,i]),0,payoff_estimates[,i])}
if(t != 1){payoff_estimates_matrix[,i,t] <- payoff_estimates_matrix[,i,t-1]}
# + {payout_matrix[,i,t-1] - contrib_matrix[,i,t-1]}}
issue_i_contribution_result = rbindlist(lapply(seq(n_agents),function(a) AgentContribution(payoff_estimate = payoff_estimates_matrix[a,i,t],
motivation = motivation_matrix[a,i,t],
# payoff = payout_matrix[a,i,t-1],
# contribution = contrib_matrix[a,i,t-1],
buyin = (contrib_matrix[-a,i,1:t]>0)/(t*n_agents),
issue = agent_issue_binary[a,i],
reciprocity = sum(reciprocity_matrix[a,i,1:t-1])/t)))
contrib_matrix[,i,t]<-issue_i_contribution_result$contribution
if(t!=periods){motivation_matrix[,i,t+1]<-issue_i_contribution_result$motivation}
payout_matrix[,i,t] <- {sum(contrib_matrix[,i,t] * issue_payoffs[i]) / {sum(agent_issue_binary[,i])}} * agent_issue_binary[,i]
reciprocity_matrix[,i,t] <- sapply(seq(n_agents),function(x) payout_matrix[x,i,t] > {motivation_matrix[x,i,t] * contrib_matrix[x,i,t] * agent_post_sharing_payoff_estimates[[x]][i]})
}
}
require(readxl)
read_excel('Downloads/PriorColleges.xlsx')
pcol = read_excel('Downloads/PriorColleges.xlsx')
grep('CSU',pcol$PRIOR_COLLEGE_1,value = T)
grep('CSU|SDSU',pcol$PRIOR_COLLEGE_1,value = T)
grep('CSU|San Dieog',pcol$PRIOR_COLLEGE_1,value = T)
grep('CSU|San Diego',pcol$PRIOR_COLLEGE_1,value = T)
grep('CSU|San Diego State',pcol$PRIOR_COLLEGE_1,value = T)
require(rJava)
getwd()
update.packages()
library(readxl)
library(rCpp)
library(Rcpp)
update.packages(repos='http://cran.rstudio.com/', ask=FALSE, checkBuilt=TRUE)
install.packages('Rcpp')
library(Rcpp)
install.packages('Rccp',type = 'source')
install.packages('Rcpp',type = 'source')
update.packages(type = 'source')
install.packages('Rcpp',type = 'source')
library(Rcpp)
install.packages('rJava',type = 'source')
remove.packages('rJava')
install.packages('rJava',type = 'source')
require(tidyverse)
require(RSelenium)
require(httr)
require(wdman)
rD <- rsDriver()
rD <- rsDriver(port = '4445')
rD <- rsDriver(port = 4445L)
remDr <- rD[["client"]]
remDr$open()
remDr$navigate("https://www.sjcog.org/DocumentCenter/")
rm(rD)
gc(rD)
rm(rD)
rm(remDr)
gc()
require(RSelenium)
require(httr)
require(wdman)
# start a chrome browser
rD <- rsDriver(port = 4445L)
remDr$navigate("http://www.google.com/ncr")
rD$open()
rD$navigate("http://www.google.com/ncr")
remDr$open()
remDr <- rD[["client"]]
remDr$open()
remDr$close("https://www.sjcog.org/DocumentCenter/")
remDr$navigate("https://www.sjcog.org/DocumentCenter/")
titems = remDr$findElements(using = 'id','t-item')
titems
titems = remDr$findElements(using = 'class','t-item')
titems
titems[[1]]
titems[[1]]$getElementText()
titems
which(sapply(titems,function(x) x$getElementText())=='Program Documents')
which(sapply(titems,function(x) x$getElementText())=='Programs')
# as test find programs tab
program_i = which(sapply(titems,function(x) x$getElementText())=='Programs')
titems[[program_i]]
titems[[program_i]]$findChildElements()
titems[[program_i]]$findChildElements(using = 'class','t-item')
titems[[program_i]]$findElements(using = 'class','t-item')
directories = remDr$findElements(using = 'class','t-item')
# as test find programs tab
program_i = which(sapply(directoris,function(x) x$getElementText())=='Programs')
# as test find programs tab
program_i = which(sapply(directories,function(x) x$getElementText())=='Programs')
subdirectories =titems[[program_i]]$findElements(using = 'class','t-item')
sapply(subdirectories,function(x) x$getElementText())
subdirectories =titems[[program_i]]$findElements(using = 'css-selector','.t-item .t-item .t-in')
subdirectories =titems[[program_i]]$findElements(using = 'css selector','.t-item .t-item .t-in')
subdirectories =directories[[program_i]]$findElements(using = 'css selector','.t-item .t-item .t-in')
sapply(subdirectories,function(x) x$getElementText())
directories[[program_i]]
directories[[program_i]]$getElementText()
directories[[program_i]]$clickElement()
remDr$findElements(using = 'css selector','.t-item .t-item .t-in')
subdirectories = remDr$findElements(using = 'css selector','.t-item .t-item .t-in')
subdirectories[[1]]$getElementText()
sapply(subdirectories,function(x) x$getElementText())
# list subdirectories:
sapply(subdirectories,function(x) x$getElementText())
transit_planning_i = which(sapply(subdirectories,function(x) x$getElementText())=='Transit Planning')
transit_planning_i
#open  folder
subdirectories[[transit_planning_i]]$clickElement()
remDr$findElements(using = 'css selector','a:contains(pdf|PDF)')
remDr$findElements(using = 'css selector','a:contains(pdf)')
remDr$findElements(using = 'css selector','a')
remDr$findElements(using = 'css selector','a:contains(pdf)')
remDr$findElements(using = 'css selector','a:contains("pdf")')
remDr$findElements(using = 'css selector','tbody')
document_table = remDr$findElements(using = 'css selector','tbody')
document_table[[1]]
document_table[[2]]
document_table = remDr$findElement(using = 'css selector','tbody')
document_table$getElementText()
document_table$getPageSource()
remDr$findElements(using = 'class','pdf')
pdfs = remDr$findElements(using = 'class','pdf')
sapply(pdfs,function(x) x$getElementText())
pdfs[[1]]$getCurrentUrl()
pdfs[[1]]$getElementAttribute(attrName = 'href')
#document href
sapply(pdfs,function(x) x$getElementAttribute(attrName = 'href'))
#document names
document_names = sapply(pdfs,function(x) x$getElementText())
#document href
document_locations = sapply(pdfs,function(x) x$getElementAttribute(attrName = 'href'))
getwd()
#note these dont' ahve pdf prefix but are PDFs
#test download
test_url = document_locations[[4]]
test_url
basename(test_url)
paste0(basename(test_url),'.pdf')
download.file(url = document_locations[[4]],destfile = paste0('~/Desktop/',basename(test_url),'.pdf'))
setwd('Documents/GitHub/klamath/')
require(data.table)
require(rvest)
require(lubridate)
require(pbapply)
start_months = mdy('01/01/2020') - months(1:(20 * 12))
end_months = start_months + months(1)
system('ln -s ~/Box/klamath/input/ ~/Documents/GitHub/klamath/')
fls = list.files('input/ceqa_month_csvs/',full.names = T,recursive = T)
flist = pblapply(fls,fread,cl = 6)
temp_dt = rbindlist(flist,use.names = T, fill = T)
temp_docs = dcast(temp_dt[,.(`SCH Number`,`Document Type`)][,.N,by=.(`SCH Number`,`Document Type`)],`SCH Number` ~ `Document Type`)
table(temp_dt$`Document Type`)
noe = temp_dt[`Document Type`=='NOE']
noe[,`NOC Project Issues`:=NULL]
noe[,`NOC Local Action`:=NULL]
fwrite(noe,'input/ceqa_NOE.csv')
sewtd('~/')
setwd('~/')
setwd('Documents/GitHub/eel/')
geocode <- function(name, address, city, state, zipcode){
# NOMINATIM SEARCH API URL
src_url <- "https://nominatim.openstreetmap.org/search?q="
# CREATE A FULL ADDRESS
addr <- paste(address, city, state, zipcode, sep = "%2C")
# CREATE A SEARCH URL BASED ON NOMINATIM API TO RETURN GEOJSON
requests <- paste0(src_url, query, "&format=geojson")
# ITERATE OVER THE URLS AND MAKE REQUEST TO THE SEARCH API
for (i in 1:length(requests)) {
# QUERY THE API TRANSFORM RESPONSE FROM JSON TO R LIST
response <- read_html(requests[i]) %>%
html_node("p") %>%
html_text() %>%
fromJSON()
# FROM THE RESPONSE EXTRACT LATITUDE AND LONGITUDE COORDINATES
lon <- response$features$geometry$coordinates[[1]][1]
lat <- response$features$geometry$coordinates[[1]][2]
# CREATE A COORDINATES DATAFRAME
if(i == 1) {
loc <- tibble(name = name[i],
address = str_replace_all(addr[i], "%2C", ","),
latitude = lat, longitude = lon)
}else{
df <- tibble(name = name[i],
address = str_replace_all(addr[i], "%2C", ","),
latitude = lat, longitude = lon)
loc <- bind_rows(loc, df)
}
}
return(loc)
}
geocode('West Addition, San Francisco')
geocode(name = 'West Addition, San Francisco')
geocode(address = 'West Addition, San Francisco')
require(ggmap)
require(ggmaps)
install.packages("ggmap")
require(ggmap)
geocode('Western Addition, San Franciscon', output = c("latlon"),
source = c( "dsk"), force = ifelse(source == "dsk", FALSE,TRUE))
rm(geocode)
geocode(name = 'Western Addition, San Franciscon', output = c("latlon"),
source = c( "dsk"), force = ifelse(source == "dsk", FALSE,TRUE))
geocode(location = 'Western Addition, San Franciscon', output = c("latlon"),
source = c( "dsk"), force = ifelse(source == "dsk", FALSE,TRUE))
system('ln -s ~/Box/eel/input/ ~/Documents/GitHub/eel')
system('ln -s ~/Box/eel/output/ ~/Documents/GitHub/eel')
library(tidyverse)
library(statnet)
library(tidyselect)
library(ggnetwork)
library(ggthemes)
library(parallel)
library(multinet)
pgks = c('tidyverse','statnet','tidyselect','ggnetwork','ggthemes','parallel','multinet')
installed.packages()[,'Package']
pgks %in% installed.packages()[,'Package']
pgks[!pgks %in% installed.packages()[,'Package']]
lapply(pgks[!pgks %in% installed.packages()[,'Package']],install.packages)
require(pgks)
?require
lapply(pgks,require,character.only = FALSE)
set = 1:14
cores = 2
seed = 24
n_sims = 1000
cd_max = 100
mc_max = 40
burn = 5000
interval = 1000
samplesize = 5000
#library(devtools)
#install_github('statnet/ergm')
run_collab = TRUE
run_tech = TRUE
run_both = TRUE
sim_collab = FALSE
sim_tech = FALSE
results = FALSE
sheet_url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vTg6ChPQBBftPdUB-IFq4OQGFyDruWwBBDyJpPmcPSiSOV1Y_bEx2XeF_wR6vkq-rY4TW2-ZAMP4alN/pub?gid=456743467&single=true&output=csv"
df = read_csv(sheet_url)
df2 = df
df <- df[!is.na(df$`Record ID`),]
df$ID = df$`Record ID`
df$Network <- df$`R02 ASW`
df <- df[df$Network>0&df$Network<15,]
df <- df[,!names(df) %in% c('R25 1 ASOW','R25 2 ASOW','R27 1 ASOW','R27 2 ASOW')]
df <- df[df$ID %in% df$ID[!sapply(df$ID,function(x) all((gather(df[df$ID==x,grepl('25|26|27',names(df))]))$value %in% c(-2,-5)))],]
df = df %>% rename(Level = Role)
role_vectors <- paste0('R05 AW ',c(1:23,35,36))
nms_role_vectors <- paste0('R05 SO ',c(24:30,32:34))
role_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vShimT8Fb2xCUXjoOaHBCCOaj3UgtHNK5jufXBeltwqnBpqrGd_5aABGQcRAc-kmXOA14LVnpZi1lba/pub?output=csv'
#roles_url = 'input/Roles_Code_Cleaned.csv'
roles_df <- read_csv(role_url)
id_roles = gather(df[,c('ID','Network','Level',role_vectors,nms_role_vectors)],Role,Response,-ID,-Network,-Level)
id_roles <- id_roles[!grepl('Other ONMS staff',id_roles$Role),]
id_roles = id_roles[id_roles$Response>0,]
id_roles = id_roles %>% select(-Response)
id_roles$Role_ID <- paste(id_roles$ID,id_roles$Role,sep='_')
id_roles$Self_Role_Name <- roles_df$Role_Name[match(id_roles$Role,roles_df$Role)]
#questions about alters
#Q25 - which ONMS staff do you communicate with: R25‐ASOW.1 - R25‐ASOW.15
#Q26 - which gov folks do you communicate with: R26‐ASOW.1 - R26‐ASOW.10
#Q27 - which non-gov folks do you communicate with: R27‐ASOW.1 - R27‐ASOW.16
role_count = id_roles %>% group_by(Network,Self_Role_Name) %>% summarise(role_count = n())
actor_details <- data.frame(ID = df$ID,Actor_Type =ifelse(df$`R01 ASW`%in%c(1,2),'Advisory Council',ifelse(df$`R01 ASW`%in%c(5,6),'Staff Member','Working Group')),
Time_Involved = df$`R03 ASOW`,Network = df$Network)
alters_df = Reduce(function(u,v) merge(u,v,all=TRUE),list(gather(df[,c('ID','Network',grep('R25',names(df),value=T))],Alter_Role,Response,-ID,-Network),
gather(df[,c('ID','Network',grep('R26',names(df),value=T))],Alter_Role,Response,-ID,-Network),
gather(df[,c('ID','Network',grep('R27',names(df),value=T))],Alter_Role,Response,-ID,-Network)))
alters_df$Response[alters_df$Response==-1] <- 0
did_not_complete = alters_df %>% group_by(ID) %>% summarise(no_see = all(Response<0)) %>% filter(no_see) %>% .$ID
df = df[!df$ID %in% did_not_complete,]
id_roles = id_roles[!id_roles$ID %in% did_not_complete,]
dyad_df <- full_join(actor_details,alters_df)
dyad_df$Alter_Role_Name <- as.factor(roles_df$Role_Name[match(dyad_df$Alter_Role,roles_df$Role)])
#dyad_df$ID = as.factor(dyad_df$ID)
dyad_df = dyad_df[dyad_df$Network<=14,]
dyad_df$Network = as.factor(dyad_df$Network)
dyad_df = dyad_df[dyad_df$Response %in% c(1:3),]
id_roles$Network = as.factor(id_roles$Network)
dyad_expansion_df = full_join(dyad_df,id_roles)
dyad_expansion_df$Self_Role_Name = as.factor(dyad_expansion_df$Self_Role_Name)
dyad_expansion_df$Self_Role_Name = fct_expand(dyad_expansion_df$Self_Role_Name,union(levels(dyad_expansion_df$Self_Role_Name),levels(dyad_expansion_df$Alter_Role_Name)))
dyad_expansion_df$Alter_Role_Name = fct_expand(dyad_expansion_df$Alter_Role_Name,union(levels(dyad_expansion_df$Self_Role_Name),levels(dyad_expansion_df$Alter_Role_Name)))
tdf = dyad_expansion_df
tdf = tdf[tdf$Self_Role_Name!='NGO',]
tdf = tdf[!is.na(tdf$ID),]
tdf$Self_Role_Name = as.character(tdf$Self_Role_Name)
tdf$Level[is.na(tdf$Level)&tdf$Actor_Type=='Advisory Council'] <- 'A'
testn = lapply(1:14,function(n) {
print(n)
n = 1
temp_df = tdf %>% filter(Network==n)
temp_df$Alter_ID = id_roles$ID[id_roles$Network==n][match(temp_df$Alter_Role_Name,id_roles$Self_Role_Name[id_roles$Network==n])]
#temp_df = temp_df[!is.na(temp_df$Alter_ID),]
mnet = multinet::ml.empty()
add.layers.ml(mnet,as.character(unique(temp_df$Level)),directed = rep(TRUE,length(unique(temp_df$Level))))
add.actors.ml(mnet,as.character(unique(temp_df$ID)))
add.actors.ml(mnet,as.character(unique(temp_df$Alter_ID)))
n1 = data.frame(grep('^W',temp_df$ID,value=T),rep('W',sum(grepl('^W',temp_df$ID))),stringsAsFactors = F);n1 = n1[!duplicated(n1),]
if(nrow(n1)>0){add.vertices.ml(mnet,n1)}
n2 = data.frame(grep('^A',temp_df$ID,value=T),rep('A',sum(grepl('^A',temp_df$ID))),stringsAsFactors = F);n2 = n2[!duplicated(n2),]
if(nrow(n2)>0){add.vertices.ml(mnet,n2)}
n3 = data.frame(grep('^S',temp_df$ID,value=T),rep('S',sum(grepl('^S',temp_df$ID))),stringsAsFactors = F);n3 = n3[!duplicated(n3),]
if(nrow(n3)>0){add.vertices.ml(mnet,n3)}
edges = data.frame(ID = temp_df$ID,Level = temp_df$Level,Alter_ID = temp_df$Alter_ID,Alter_Level = str_extract(temp_df$Alter_ID,'^[A-Z]{1}'),stringsAsFactors = F)
isols = edges[is.na(edges$Alter_Level),]
edges = edges[!is.na(edges$Alter_Level),]
print(nrow(isols)/(nrow(edges)+nrow(isols)))
#isols <- isols[!isols$temp_df.ID %in% edges$temp_df.ID,]
add.edges.ml(mnet,edges)
mnet})
pgks = c('tidyverse','statnet','tidyselect','ggnetwork','ggthemes','parallel','multinet','fergm')
lapply(pgks[!pgks %in% installed.packages()[,'Package']],install.packages)
?install.packages
lapply(pgks[!pgks %in% installed.packages()[,'Package']],install.packages,type = 'source')
install.packages('extrafont')
install.packages('rstan')
devtools::install_github('stan-dev/rstan')
devtools::install_github('https://github.com/stan-dev/rstan')
install.packages('devtools')
install.packages("devtools")
devtools::install_github('stan-dev/rstan')
devtools::install_github('stan-dev','rstan')
#setwd('~/Documents/Github/eel')
#system('ln -s ~/Box/eel/input/ ~/Documents/GitHub/eel')
#system('ln -s ~/Box/eel/output/ ~/Documents/GitHub/eel')
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("Rcpp", repos = "https://rcppcore.github.io/drat")
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
Sys.setenv(MAKEFLAGS = "-j4") # four cores used
install.packages("rstan", type = "source")
remotes::install_github("stan-dev/rstan", ref = "develop",
subdir = "rstan/rstan", build_opts = "")
pkgbuild::has_build_tools(debug = TRUE)
require('Rccp')
require('Rcpp')
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
remotes::install_github("stan-dev/rstan", ref = "develop",
subdir = "rstan/rstan", build_opts = "")
install.packages(c("StanHeaders", "rstan"), type = "source")
#setwd('~/Documents/Github/eel')
#system('ln -s ~/Box/eel/input/ ~/Documents/GitHub/eel')
#system('ln -s ~/Box/eel/output/ ~/Documents/GitHub/eel')
remove.packages("rstan")
#setwd('~/Documents/Github/eel')
#system('ln -s ~/Box/eel/input/ ~/Documents/GitHub/eel')
#system('ln -s ~/Box/eel/output/ ~/Documents/GitHub/eel')
remove.packages("Rcpp")
if (file.exists(".RData")) file.remove(".RData")
install.packages("Rcpp", repos = "https://rcppcore.github.io/drat")
install.packages("Rcpp", repos = "https://rcppcore.github.io/drat",dependencies = T)
file.edit("~/.Renviron")
install.packages(c('RcppArmadillo'))
library('Rcpp')
remotes::install_github("stan-dev/rstan", ref = "develop",
subdir = "rstan/rstan", build_opts = "")
install.packages("rstan")
library(rstan)
